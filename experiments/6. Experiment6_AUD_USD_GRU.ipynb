{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAnbvZRq-82s"
   },
   "source": [
    "Implementation of LSTM Model on AUD_USD(H1) prediction of the close price 1 hour ahead based on data of previous 24 hours\n",
    "\n",
    "## 1. Data Preparation\n",
    "\n",
    "### 1.1 Read in data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW_f99ou_A41",
    "outputId": "10be9b4d-2c47-44bd-f083-abce50e9437f"
   },
   "outputs": [],
   "source": [
    "## Mount google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fc-Rd2qb-82y"
   },
   "outputs": [],
   "source": [
    "# import talib as ta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from utils import series_to_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMvkTVZB-828"
   },
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DOSWIAulBRpc"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('AUD_USD_H1_withindicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "86zz27H0DUkJ",
    "outputId": "56476ddd-48fe-4590-e496-1c0edf2b6a48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>upperband</th>\n",
       "      <th>middleband</th>\n",
       "      <th>lowerband</th>\n",
       "      <th>dema</th>\n",
       "      <th>ema</th>\n",
       "      <th>ht</th>\n",
       "      <th>...</th>\n",
       "      <th>cdlspinningtop</th>\n",
       "      <th>cdlstalledpattern</th>\n",
       "      <th>cdlsticksandwich</th>\n",
       "      <th>cdltakuri</th>\n",
       "      <th>cdltasukigap</th>\n",
       "      <th>cdlthrusting</th>\n",
       "      <th>cdltristar</th>\n",
       "      <th>cdlunique3river</th>\n",
       "      <th>cdlupsidegap2crows</th>\n",
       "      <th>cdlxsidegap3methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.76660</td>\n",
       "      <td>0.76740</td>\n",
       "      <td>0.76620</td>\n",
       "      <td>0.76690</td>\n",
       "      <td>0.772125</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.762217</td>\n",
       "      <td>0.765635</td>\n",
       "      <td>0.766812</td>\n",
       "      <td>0.766752</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76700</td>\n",
       "      <td>0.76740</td>\n",
       "      <td>0.76680</td>\n",
       "      <td>0.76720</td>\n",
       "      <td>0.771836</td>\n",
       "      <td>0.767046</td>\n",
       "      <td>0.762255</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.766843</td>\n",
       "      <td>0.766669</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76720</td>\n",
       "      <td>0.76720</td>\n",
       "      <td>0.76630</td>\n",
       "      <td>0.76710</td>\n",
       "      <td>0.771420</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.762363</td>\n",
       "      <td>0.765913</td>\n",
       "      <td>0.766864</td>\n",
       "      <td>0.766620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76720</td>\n",
       "      <td>0.76750</td>\n",
       "      <td>0.76620</td>\n",
       "      <td>0.76660</td>\n",
       "      <td>0.771182</td>\n",
       "      <td>0.766775</td>\n",
       "      <td>0.762368</td>\n",
       "      <td>0.765948</td>\n",
       "      <td>0.766843</td>\n",
       "      <td>0.766482</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76660</td>\n",
       "      <td>0.76740</td>\n",
       "      <td>0.76630</td>\n",
       "      <td>0.76700</td>\n",
       "      <td>0.770581</td>\n",
       "      <td>0.766596</td>\n",
       "      <td>0.762610</td>\n",
       "      <td>0.766044</td>\n",
       "      <td>0.766855</td>\n",
       "      <td>0.766334</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102554</th>\n",
       "      <td>0.77218</td>\n",
       "      <td>0.77353</td>\n",
       "      <td>0.77122</td>\n",
       "      <td>0.77186</td>\n",
       "      <td>0.792204</td>\n",
       "      <td>0.781209</td>\n",
       "      <td>0.770214</td>\n",
       "      <td>0.773963</td>\n",
       "      <td>0.780610</td>\n",
       "      <td>0.786190</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102555</th>\n",
       "      <td>0.77190</td>\n",
       "      <td>0.77235</td>\n",
       "      <td>0.77064</td>\n",
       "      <td>0.77088</td>\n",
       "      <td>0.791442</td>\n",
       "      <td>0.780397</td>\n",
       "      <td>0.769351</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.779832</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102556</th>\n",
       "      <td>0.77092</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>0.76924</td>\n",
       "      <td>0.76947</td>\n",
       "      <td>0.791248</td>\n",
       "      <td>0.779687</td>\n",
       "      <td>0.768125</td>\n",
       "      <td>0.771955</td>\n",
       "      <td>0.779003</td>\n",
       "      <td>0.784054</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102557</th>\n",
       "      <td>0.76944</td>\n",
       "      <td>0.77106</td>\n",
       "      <td>0.76926</td>\n",
       "      <td>0.77038</td>\n",
       "      <td>0.790680</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.767292</td>\n",
       "      <td>0.771195</td>\n",
       "      <td>0.778313</td>\n",
       "      <td>0.783281</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102558</th>\n",
       "      <td>0.77120</td>\n",
       "      <td>0.77232</td>\n",
       "      <td>0.77082</td>\n",
       "      <td>0.77203</td>\n",
       "      <td>0.789766</td>\n",
       "      <td>0.778336</td>\n",
       "      <td>0.766906</td>\n",
       "      <td>0.770799</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.782729</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102559 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open     high      low    close  upperband  middleband  lowerband  \\\n",
       "0       0.76660  0.76740  0.76620  0.76690   0.772125    0.767171   0.762217   \n",
       "1       0.76700  0.76740  0.76680  0.76720   0.771836    0.767046   0.762255   \n",
       "2       0.76720  0.76720  0.76630  0.76710   0.771420    0.766892   0.762363   \n",
       "3       0.76720  0.76750  0.76620  0.76660   0.771182    0.766775   0.762368   \n",
       "4       0.76660  0.76740  0.76630  0.76700   0.770581    0.766596   0.762610   \n",
       "...         ...      ...      ...      ...        ...         ...        ...   \n",
       "102554  0.77218  0.77353  0.77122  0.77186   0.792204    0.781209   0.770214   \n",
       "102555  0.77190  0.77235  0.77064  0.77088   0.791442    0.780397   0.769351   \n",
       "102556  0.77092  0.77152  0.76924  0.76947   0.791248    0.779687   0.768125   \n",
       "102557  0.76944  0.77106  0.76926  0.77038   0.790680    0.778986   0.767292   \n",
       "102558  0.77120  0.77232  0.77082  0.77203   0.789766    0.778336   0.766906   \n",
       "\n",
       "            dema       ema        ht  ...  cdlspinningtop  cdlstalledpattern  \\\n",
       "0       0.765635  0.766812  0.766752  ...             100                  0   \n",
       "1       0.765789  0.766843  0.766669  ...               0                  0   \n",
       "2       0.765913  0.766864  0.766620  ...               0                  0   \n",
       "3       0.765948  0.766843  0.766482  ...               0                  0   \n",
       "4       0.766044  0.766855  0.766334  ...               0                  0   \n",
       "...          ...       ...       ...  ...             ...                ...   \n",
       "102554  0.773963  0.780610  0.786190  ...            -100                  0   \n",
       "102555  0.773000  0.779832  0.785098  ...               0                  0   \n",
       "102556  0.771955  0.779003  0.784054  ...               0                  0   \n",
       "102557  0.771195  0.778313  0.783281  ...               0                  0   \n",
       "102558  0.770799  0.777810  0.782729  ...               0                  0   \n",
       "\n",
       "        cdlsticksandwich  cdltakuri  cdltasukigap  cdlthrusting  cdltristar  \\\n",
       "0                      0          0             0             0           0   \n",
       "1                      0          0             0             0           0   \n",
       "2                      0        100             0             0           0   \n",
       "3                      0          0             0             0           0   \n",
       "4                      0          0             0             0           0   \n",
       "...                  ...        ...           ...           ...         ...   \n",
       "102554                 0          0             0             0           0   \n",
       "102555                 0          0             0             0           0   \n",
       "102556                 0          0             0             0           0   \n",
       "102557                 0          0             0             0           0   \n",
       "102558                 0          0             0             0           0   \n",
       "\n",
       "        cdlunique3river  cdlupsidegap2crows  cdlxsidegap3methods  \n",
       "0                     0                   0                    0  \n",
       "1                     0                   0                    0  \n",
       "2                     0                   0                    0  \n",
       "3                     0                   0                    0  \n",
       "4                     0                   0                    0  \n",
       "...                 ...                 ...                  ...  \n",
       "102554                0                   0                    0  \n",
       "102555                0                   0                    0  \n",
       "102556                0                   0                    0  \n",
       "102557                0                   0                    0  \n",
       "102558                0                   0                    0  \n",
       "\n",
       "[102559 rows x 139 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0AXo8mnT-828"
   },
   "outputs": [],
   "source": [
    "train_split_frac = 0.8\n",
    "val_split_frac = 0.9\n",
    "\n",
    "train_split = int(train_split_frac * int(data.shape[0]))  ## end of train index (exclusive)\n",
    "val_split = int(val_split_frac * int(data.shape[0]))      ## end of val index (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kuYA4KxQ-828"
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "past = 24\n",
    "future = 1\n",
    "learning_rate = 0.00001\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "y = data[['close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzmHYict-828"
   },
   "source": [
    "### 2.1 Train - validation - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1J8FEQXe-828"
   },
   "outputs": [],
   "source": [
    "training_data = data[: train_split]\n",
    "validation_data = data[train_split: val_split]\n",
    "test_data = data[val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O96fNXrp-829",
    "outputId": "f77a07af-9dba-44b0-ec96-d3a69a8ae37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training_data:    (82047, 139)\n",
      "Shape of validation_data:  (10256, 139)\n",
      "Shape of test_data:        (10256, 139)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training_data:   ', training_data.shape)\n",
    "print('Shape of validation_data: ', validation_data.shape)\n",
    "print('Shape of test_data:       ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0afYdtVc-829"
   },
   "source": [
    "### 2.2 Standardisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rffWzdfO-829"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xlFwGJYa-829"
   },
   "outputs": [],
   "source": [
    "training_data = scaler.fit_transform(training_data)\n",
    "validation_data = scaler.transform(validation_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXhSLQy1-829"
   },
   "source": [
    "### 2.3 Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hWPFGek2-829"
   },
   "outputs": [],
   "source": [
    "train_y_start = past + future\n",
    "train_y_end = train_y_start + train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8PdVpLjK-829"
   },
   "outputs": [],
   "source": [
    "x_train = training_data\n",
    "y_train = y.iloc[train_y_start: train_y_end].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KcDMuAGc-82-"
   },
   "outputs": [],
   "source": [
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w0-rFyyF-82-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5i9VngT-82-"
   },
   "source": [
    "### 2.4 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r4goKEZX-82-"
   },
   "outputs": [],
   "source": [
    "val_y_start = train_y_end\n",
    "val_y_end = train_y_start + val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sxSeqB5Y-82-"
   },
   "outputs": [],
   "source": [
    "x_val = validation_data\n",
    "y_val = y.iloc[val_y_start: val_y_end].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rDbkebH8-82-"
   },
   "outputs": [],
   "source": [
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Un7TFjj-82-"
   },
   "source": [
    "### 2.5 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4U9uUo65-82_"
   },
   "outputs": [],
   "source": [
    "x_end = len(test_data) - past - future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PJioXbRV-82_"
   },
   "outputs": [],
   "source": [
    "test_y_start = val_y_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DGb2K5Tl-82_"
   },
   "outputs": [],
   "source": [
    "x_test = test_data[: x_end]\n",
    "y_test = y.iloc[test_y_start: ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pmUdGQZj-82_"
   },
   "outputs": [],
   "source": [
    "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrHF6wiJ-82_"
   },
   "source": [
    "### 2.4 Input and output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcVDGwh1-82_",
    "outputId": "41ec916d-03e0-4389-f4ed-0d9c4f81dcaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (256, 24, 139)\n",
      "Target shape: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K39lUDyk-82_"
   },
   "source": [
    "## 3. Experiment1: LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fbXnfmZF-82_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq1Y_tG_-83A"
   },
   "source": [
    "### 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5j1en1TA-83A",
    "outputId": "513bdb95-9ebb-40fe-cf10-9b36dbdeb0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 139)]         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 200)               204600    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 204,801\n",
      "Trainable params: 204,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "gru_out = keras.layers.GRU(200)(inputs)\n",
    "outputs = keras.layers.Dense(1)(gru_out)\n",
    "\n",
    "model1 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwq9nQCX-83A",
    "outputId": "c19314b7-a5bc-4ca2-fbfd-33a949d3fa37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "321/321 [==============================] - 32s 95ms/step - loss: 0.0517 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00471, saving model to model_checkpoint_gru.h5\n",
      "Epoch 2/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00471 to 0.00173, saving model to model_checkpoint_gru.h5\n",
      "Epoch 3/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00173 to 0.00119, saving model to model_checkpoint_gru.h5\n",
      "Epoch 4/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00119 to 0.00108, saving model to model_checkpoint_gru.h5\n",
      "Epoch 5/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00108\n",
      "Epoch 6/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 9.5215e-04 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00108\n",
      "Epoch 7/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.4233e-04 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00108\n",
      "Epoch 8/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 7.6161e-04 - val_loss: 0.0014\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00108\n",
      "Epoch 9/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 7.0256e-04 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00108\n",
      "Epoch 10/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 6.6119e-04 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00108\n",
      "Epoch 11/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.3327e-04 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00108\n",
      "Epoch 12/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.1353e-04 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00108\n",
      "Epoch 13/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 5.9678e-04 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00108\n",
      "Epoch 14/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 5.7923e-04 - val_loss: 0.0015\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00108\n",
      "Epoch 15/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.5878e-04 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00108\n",
      "Epoch 16/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.3470e-04 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00108\n",
      "Epoch 17/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.0715e-04 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00108 to 0.00107, saving model to model_checkpoint_gru.h5\n",
      "Epoch 18/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.7678e-04 - val_loss: 9.2957e-04\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00107 to 0.00093, saving model to model_checkpoint_gru.h5\n",
      "Epoch 19/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 4.4443e-04 - val_loss: 8.0577e-04\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00093 to 0.00081, saving model to model_checkpoint_gru.h5\n",
      "Epoch 20/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1110e-04 - val_loss: 6.9877e-04\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00081 to 0.00070, saving model to model_checkpoint_gru.h5\n",
      "Epoch 21/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7795e-04 - val_loss: 6.0709e-04\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00070 to 0.00061, saving model to model_checkpoint_gru.h5\n",
      "Epoch 22/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.4646e-04 - val_loss: 5.2049e-04\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00061 to 0.00052, saving model to model_checkpoint_gru.h5\n",
      "Epoch 23/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.1857e-04 - val_loss: 4.2647e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00052 to 0.00043, saving model to model_checkpoint_gru.h5\n",
      "Epoch 24/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.9640e-04 - val_loss: 3.2644e-04\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00043 to 0.00033, saving model to model_checkpoint_gru.h5\n",
      "Epoch 25/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.8101e-04 - val_loss: 2.3701e-04\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00033 to 0.00024, saving model to model_checkpoint_gru.h5\n",
      "Epoch 26/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.7152e-04 - val_loss: 1.7154e-04\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00024 to 0.00017, saving model to model_checkpoint_gru.h5\n",
      "Epoch 27/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.6582e-04 - val_loss: 1.3030e-04\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00017 to 0.00013, saving model to model_checkpoint_gru.h5\n",
      "Epoch 28/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.6182e-04 - val_loss: 1.0681e-04\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00013 to 0.00011, saving model to model_checkpoint_gru.h5\n",
      "Epoch 29/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.5781e-04 - val_loss: 9.4777e-05\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00011 to 0.00009, saving model to model_checkpoint_gru.h5\n",
      "Epoch 30/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.5230e-04 - val_loss: 9.0178e-05\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00009 to 0.00009, saving model to model_checkpoint_gru.h5\n",
      "Epoch 31/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.4428e-04 - val_loss: 9.0925e-05\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00009\n",
      "Epoch 32/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.3362e-04 - val_loss: 9.5762e-05\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00009\n",
      "Epoch 33/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.2112e-04 - val_loss: 1.0313e-04\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00009\n",
      "Epoch 34/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.0813e-04 - val_loss: 1.1065e-04\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00009\n",
      "Epoch 35/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.9600e-04 - val_loss: 1.1550e-04\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00009\n",
      "Epoch 36/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.8570e-04 - val_loss: 1.1558e-04\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00009\n",
      "Epoch 37/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.7759e-04 - val_loss: 1.1051e-04\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00009\n",
      "Epoch 38/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 1.7153e-04 - val_loss: 1.0172e-04\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00009\n",
      "Epoch 39/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.6708e-04 - val_loss: 9.1462e-05\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00009\n",
      "Epoch 40/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.6368e-04 - val_loss: 8.1686e-05\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00009 to 0.00008, saving model to model_checkpoint_gru.h5\n",
      "Epoch 41/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 1.6090e-04 - val_loss: 7.3432e-05\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00008 to 0.00007, saving model to model_checkpoint_gru.h5\n",
      "Epoch 42/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 1.5840e-04 - val_loss: 6.6909e-05\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00007 to 0.00007, saving model to model_checkpoint_gru.h5\n",
      "Epoch 43/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.5602e-04 - val_loss: 6.1822e-05\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00007 to 0.00006, saving model to model_checkpoint_gru.h5\n",
      "Epoch 44/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.5370e-04 - val_loss: 5.7716e-05\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00006 to 0.00006, saving model to model_checkpoint_gru.h5\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 29s 90ms/step - loss: 1.5146e-04 - val_loss: 5.4196e-05\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00006 to 0.00005, saving model to model_checkpoint_gru.h5\n",
      "Epoch 46/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.4931e-04 - val_loss: 5.1005e-05\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00005 to 0.00005, saving model to model_checkpoint_gru.h5\n",
      "Epoch 47/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.4725e-04 - val_loss: 4.8032e-05\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00005 to 0.00005, saving model to model_checkpoint_gru.h5\n",
      "Epoch 48/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.4526e-04 - val_loss: 4.5267e-05\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00005 to 0.00005, saving model to model_checkpoint_gru.h5\n",
      "Epoch 49/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.4333e-04 - val_loss: 4.2747e-05\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00005 to 0.00004, saving model to model_checkpoint_gru.h5\n",
      "Epoch 50/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.4143e-04 - val_loss: 4.0511e-05\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00004 to 0.00004, saving model to model_checkpoint_gru.h5\n",
      "Epoch 51/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.3957e-04 - val_loss: 3.8571e-05\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00004 to 0.00004, saving model to model_checkpoint_gru.h5\n",
      "Epoch 52/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.3773e-04 - val_loss: 3.6914e-05\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00004 to 0.00004, saving model to model_checkpoint_gru.h5\n",
      "Epoch 53/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.3594e-04 - val_loss: 3.5502e-05\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00004 to 0.00004, saving model to model_checkpoint_gru.h5\n",
      "Epoch 54/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.3420e-04 - val_loss: 3.4289e-05\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00004 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 55/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.3251e-04 - val_loss: 3.3227e-05\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 56/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.3087e-04 - val_loss: 3.2272e-05\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 57/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.2928e-04 - val_loss: 3.1390e-05\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 58/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.2774e-04 - val_loss: 3.0558e-05\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 59/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.2624e-04 - val_loss: 2.9760e-05\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 60/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.2477e-04 - val_loss: 2.8989e-05\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 61/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.2333e-04 - val_loss: 2.8247e-05\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 62/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.2193e-04 - val_loss: 2.7534e-05\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 63/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 1.2054e-04 - val_loss: 2.6856e-05\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 64/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.1919e-04 - val_loss: 2.6216e-05\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 65/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.1787e-04 - val_loss: 2.5614e-05\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 66/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1657e-04 - val_loss: 2.5051e-05\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint_gru.h5\n",
      "Epoch 67/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1531e-04 - val_loss: 2.4524e-05\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00003 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 68/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1408e-04 - val_loss: 2.4029e-05\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 69/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1288e-04 - val_loss: 2.3563e-05\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 70/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1172e-04 - val_loss: 2.3123e-05\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 71/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.1059e-04 - val_loss: 2.2703e-05\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 72/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0948e-04 - val_loss: 2.2303e-05\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 73/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0841e-04 - val_loss: 2.1921e-05\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 74/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0735e-04 - val_loss: 2.1554e-05\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 75/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0632e-04 - val_loss: 2.1202e-05\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 76/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.0531e-04 - val_loss: 2.0863e-05\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 77/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.0432e-04 - val_loss: 2.0538e-05\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 78/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 1.0335e-04 - val_loss: 2.0225e-05\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 79/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0240e-04 - val_loss: 1.9925e-05\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 80/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0148e-04 - val_loss: 1.9635e-05\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 81/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 1.0058e-04 - val_loss: 1.9355e-05\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 82/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 9.9696e-05 - val_loss: 1.9086e-05\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 83/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 9.8838e-05 - val_loss: 1.8825e-05\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 84/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 9.8001e-05 - val_loss: 1.8573e-05\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 85/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.7185e-05 - val_loss: 1.8329e-05\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 86/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.6390e-05 - val_loss: 1.8092e-05\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 87/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 9.5615e-05 - val_loss: 1.7862e-05\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 88/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.4859e-05 - val_loss: 1.7638e-05\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 89/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.4122e-05 - val_loss: 1.7421e-05\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 90/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.3404e-05 - val_loss: 1.7210e-05\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 91/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.2704e-05 - val_loss: 1.7004e-05\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 92/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.2023e-05 - val_loss: 1.6804e-05\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 93/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.1361e-05 - val_loss: 1.6609e-05\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 94/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 9.0718e-05 - val_loss: 1.6418e-05\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 95/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 9.0094e-05 - val_loss: 1.6233e-05\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 96/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.9489e-05 - val_loss: 1.6052e-05\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 97/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.8904e-05 - val_loss: 1.5875e-05\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 98/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.8337e-05 - val_loss: 1.5703e-05\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 99/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.7790e-05 - val_loss: 1.5535e-05\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 100/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.7262e-05 - val_loss: 1.5370e-05\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 101/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.6753e-05 - val_loss: 1.5210e-05\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 102/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.6263e-05 - val_loss: 1.5053e-05\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00002 to 0.00002, saving model to model_checkpoint_gru.h5\n",
      "Epoch 103/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.5792e-05 - val_loss: 1.4900e-05\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00002 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 104/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.5338e-05 - val_loss: 1.4750e-05\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 105/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.4901e-05 - val_loss: 1.4603e-05\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 106/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.4481e-05 - val_loss: 1.4460e-05\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 107/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 8.4076e-05 - val_loss: 1.4319e-05\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 108/1000\n",
      "321/321 [==============================] - 32s 100ms/step - loss: 8.3685e-05 - val_loss: 1.4182e-05\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 109/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 8.3308e-05 - val_loss: 1.4047e-05\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 110/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.2941e-05 - val_loss: 1.3915e-05\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 111/1000\n",
      "321/321 [==============================] - 31s 95ms/step - loss: 8.2587e-05 - val_loss: 1.3786e-05\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 112/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.2241e-05 - val_loss: 1.3659e-05\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 113/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 8.1903e-05 - val_loss: 1.3535e-05\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 114/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 8.1572e-05 - val_loss: 1.3414e-05\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 115/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 8.1248e-05 - val_loss: 1.3294e-05\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 116/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 8.0929e-05 - val_loss: 1.3178e-05\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 117/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 8.0615e-05 - val_loss: 1.3063e-05\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 118/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 8.0306e-05 - val_loss: 1.2950e-05\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 119/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 7.9999e-05 - val_loss: 1.2840e-05\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 120/1000\n",
      "321/321 [==============================] - 31s 98ms/step - loss: 7.9697e-05 - val_loss: 1.2732e-05\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 121/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 7.9396e-05 - val_loss: 1.2625e-05\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 122/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.9099e-05 - val_loss: 1.2521e-05\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 88ms/step - loss: 7.8805e-05 - val_loss: 1.2419e-05\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 124/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.8514e-05 - val_loss: 1.2318e-05\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 125/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 7.8226e-05 - val_loss: 1.2219e-05\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 126/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 7.7941e-05 - val_loss: 1.2123e-05\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 127/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 7.7658e-05 - val_loss: 1.2027e-05\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 128/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.7380e-05 - val_loss: 1.1934e-05\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 129/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.7104e-05 - val_loss: 1.1842e-05\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 130/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.6832e-05 - val_loss: 1.1752e-05\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 131/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.6563e-05 - val_loss: 1.1663e-05\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 132/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.6297e-05 - val_loss: 1.1576e-05\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 133/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.6035e-05 - val_loss: 1.1490e-05\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 134/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.5776e-05 - val_loss: 1.1406e-05\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 135/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.5520e-05 - val_loss: 1.1323e-05\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 136/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.5267e-05 - val_loss: 1.1242e-05\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 137/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.5017e-05 - val_loss: 1.1161e-05\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 138/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.4770e-05 - val_loss: 1.1083e-05\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 139/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.4525e-05 - val_loss: 1.1005e-05\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 140/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 7.4284e-05 - val_loss: 1.0929e-05\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 141/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 7.4044e-05 - val_loss: 1.0854e-05\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 142/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 7.3808e-05 - val_loss: 1.0780e-05\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 143/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.3573e-05 - val_loss: 1.0707e-05\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 144/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 7.3340e-05 - val_loss: 1.0636e-05\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 145/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.3110e-05 - val_loss: 1.0565e-05\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 146/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 7.2882e-05 - val_loss: 1.0496e-05\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 147/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.2656e-05 - val_loss: 1.0428e-05\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 148/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.2432e-05 - val_loss: 1.0360e-05\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 149/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 7.2211e-05 - val_loss: 1.0294e-05\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 150/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 7.1991e-05 - val_loss: 1.0229e-05\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 151/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 7.1774e-05 - val_loss: 1.0165e-05\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 152/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 7.1560e-05 - val_loss: 1.0102e-05\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 153/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 7.1347e-05 - val_loss: 1.0039e-05\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 154/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 7.1137e-05 - val_loss: 9.9776e-06\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 155/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 7.0928e-05 - val_loss: 9.9170e-06\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 156/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 7.0722e-05 - val_loss: 9.8572e-06\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 157/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 7.0518e-05 - val_loss: 9.7984e-06\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 158/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 7.0316e-05 - val_loss: 9.7403e-06\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 159/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 7.0115e-05 - val_loss: 9.6829e-06\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 160/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.9916e-05 - val_loss: 9.6265e-06\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 161/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.9719e-05 - val_loss: 9.5708e-06\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 89ms/step - loss: 6.9523e-05 - val_loss: 9.5158e-06\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 163/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 6.9329e-05 - val_loss: 9.4617e-06\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 164/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 6.9136e-05 - val_loss: 9.4082e-06\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 165/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8944e-05 - val_loss: 9.3556e-06\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 166/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8754e-05 - val_loss: 9.3035e-06\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 167/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8564e-05 - val_loss: 9.2523e-06\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 168/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8376e-05 - val_loss: 9.2016e-06\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 169/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8190e-05 - val_loss: 9.1517e-06\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 170/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.8003e-05 - val_loss: 9.1023e-06\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 171/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.7819e-05 - val_loss: 9.0537e-06\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 172/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.7636e-05 - val_loss: 9.0056e-06\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 173/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.7454e-05 - val_loss: 8.9582e-06\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 174/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.7273e-05 - val_loss: 8.9114e-06\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 175/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.7093e-05 - val_loss: 8.8652e-06\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 176/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6915e-05 - val_loss: 8.8196e-06\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 177/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6737e-05 - val_loss: 8.7746e-06\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 178/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6561e-05 - val_loss: 8.7302e-06\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 179/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6386e-05 - val_loss: 8.6862e-06\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 180/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6212e-05 - val_loss: 8.6429e-06\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 181/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.6039e-05 - val_loss: 8.6000e-06\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 182/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.5868e-05 - val_loss: 8.5576e-06\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 183/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 6.5698e-05 - val_loss: 8.5157e-06\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 184/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.5528e-05 - val_loss: 8.4744e-06\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 185/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.5360e-05 - val_loss: 8.4335e-06\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 186/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.5193e-05 - val_loss: 8.3932e-06\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 187/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.5026e-05 - val_loss: 8.3533e-06\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 188/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.4862e-05 - val_loss: 8.3139e-06\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 189/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.4698e-05 - val_loss: 8.2749e-06\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 190/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.4534e-05 - val_loss: 8.2364e-06\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 191/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.4372e-05 - val_loss: 8.1984e-06\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 192/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.4211e-05 - val_loss: 8.1607e-06\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 193/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.4051e-05 - val_loss: 8.1234e-06\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 194/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.3891e-05 - val_loss: 8.0865e-06\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 195/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.3732e-05 - val_loss: 8.0500e-06\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 196/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.3573e-05 - val_loss: 8.0140e-06\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 197/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.3416e-05 - val_loss: 7.9784e-06\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 198/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.3259e-05 - val_loss: 7.9432e-06\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 199/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.3102e-05 - val_loss: 7.9084e-06\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 200/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.2947e-05 - val_loss: 7.8740e-06\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2792e-05 - val_loss: 7.8399e-06\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 202/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2638e-05 - val_loss: 7.8062e-06\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 203/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2486e-05 - val_loss: 7.7728e-06\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 204/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2334e-05 - val_loss: 7.7399e-06\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 205/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2183e-05 - val_loss: 7.7073e-06\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 206/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.2033e-05 - val_loss: 7.6750e-06\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 207/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.1884e-05 - val_loss: 7.6430e-06\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 208/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.1735e-05 - val_loss: 7.6113e-06\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 209/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.1588e-05 - val_loss: 7.5800e-06\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 210/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.1442e-05 - val_loss: 7.5490e-06\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 211/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 6.1297e-05 - val_loss: 7.5183e-06\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 212/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.1153e-05 - val_loss: 7.4879e-06\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 213/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 6.1010e-05 - val_loss: 7.4576e-06\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 214/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.0868e-05 - val_loss: 7.4278e-06\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 215/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.0727e-05 - val_loss: 7.3982e-06\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 216/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 6.0587e-05 - val_loss: 7.3690e-06\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 217/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.0447e-05 - val_loss: 7.3399e-06\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 218/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 6.0308e-05 - val_loss: 7.3111e-06\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 219/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 6.0168e-05 - val_loss: 7.2827e-06\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 220/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 6.0031e-05 - val_loss: 7.2545e-06\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 221/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 5.9893e-05 - val_loss: 7.2266e-06\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 222/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 5.9757e-05 - val_loss: 7.1989e-06\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 223/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 5.9621e-05 - val_loss: 7.1715e-06\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 224/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 5.9485e-05 - val_loss: 7.1443e-06\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 225/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 5.9350e-05 - val_loss: 7.1174e-06\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 226/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 5.9215e-05 - val_loss: 7.0907e-06\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 227/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 5.9081e-05 - val_loss: 7.0644e-06\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 228/1000\n",
      "321/321 [==============================] - 37s 114ms/step - loss: 5.8948e-05 - val_loss: 7.0382e-06\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 229/1000\n",
      "321/321 [==============================] - 43s 135ms/step - loss: 5.8814e-05 - val_loss: 7.0123e-06\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 230/1000\n",
      "321/321 [==============================] - 47s 145ms/step - loss: 5.8682e-05 - val_loss: 6.9867e-06\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 231/1000\n",
      "321/321 [==============================] - 47s 148ms/step - loss: 5.8551e-05 - val_loss: 6.9612e-06\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 232/1000\n",
      "321/321 [==============================] - 49s 153ms/step - loss: 5.8420e-05 - val_loss: 6.9360e-06\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 233/1000\n",
      "321/321 [==============================] - 48s 151ms/step - loss: 5.8289e-05 - val_loss: 6.9111e-06\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 234/1000\n",
      "321/321 [==============================] - 67s 209ms/step - loss: 5.8159e-05 - val_loss: 6.8863e-06\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 235/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 5.8031e-05 - val_loss: 6.8618e-06\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 236/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 5.7902e-05 - val_loss: 6.8376e-06\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 237/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 5.7774e-05 - val_loss: 6.8135e-06\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 238/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.7647e-05 - val_loss: 6.7895e-06\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 239/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.7520e-05 - val_loss: 6.7658e-06\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 88ms/step - loss: 5.7393e-05 - val_loss: 6.7424e-06\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 241/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.7267e-05 - val_loss: 6.7192e-06\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 242/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.7141e-05 - val_loss: 6.6962e-06\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 243/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.7016e-05 - val_loss: 6.6735e-06\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 244/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.6891e-05 - val_loss: 6.6509e-06\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 245/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.6766e-05 - val_loss: 6.6286e-06\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 246/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.6642e-05 - val_loss: 6.6063e-06\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 247/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 5.6519e-05 - val_loss: 6.5843e-06\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 248/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.6395e-05 - val_loss: 6.5625e-06\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 249/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.6273e-05 - val_loss: 6.5409e-06\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 250/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.6151e-05 - val_loss: 6.5195e-06\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 251/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.6029e-05 - val_loss: 6.4981e-06\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 252/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.5907e-05 - val_loss: 6.4772e-06\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 253/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.5786e-05 - val_loss: 6.4564e-06\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 254/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.5666e-05 - val_loss: 6.4356e-06\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 255/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.5547e-05 - val_loss: 6.4151e-06\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 256/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.5428e-05 - val_loss: 6.3948e-06\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 257/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.5309e-05 - val_loss: 6.3747e-06\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 258/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.5192e-05 - val_loss: 6.3545e-06\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 259/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.5075e-05 - val_loss: 6.3347e-06\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 260/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.4958e-05 - val_loss: 6.3149e-06\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 261/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.4843e-05 - val_loss: 6.2954e-06\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 262/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.4727e-05 - val_loss: 6.2760e-06\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 263/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.4612e-05 - val_loss: 6.2567e-06\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 264/1000\n",
      "321/321 [==============================] - 31s 95ms/step - loss: 5.4497e-05 - val_loss: 6.2376e-06\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 265/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 5.4384e-05 - val_loss: 6.2186e-06\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 266/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.4271e-05 - val_loss: 6.1997e-06\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 267/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.4157e-05 - val_loss: 6.1810e-06\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 268/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.4045e-05 - val_loss: 6.1625e-06\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 269/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.3934e-05 - val_loss: 6.1440e-06\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 270/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.3822e-05 - val_loss: 6.1258e-06\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 271/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.3710e-05 - val_loss: 6.1078e-06\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 272/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.3598e-05 - val_loss: 6.0899e-06\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 273/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.3487e-05 - val_loss: 6.0721e-06\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 274/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.3376e-05 - val_loss: 6.0546e-06\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 275/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.3267e-05 - val_loss: 6.0372e-06\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 276/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.3157e-05 - val_loss: 6.0200e-06\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 277/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.3049e-05 - val_loss: 6.0028e-06\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 278/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.2941e-05 - val_loss: 5.9857e-06\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2835e-05 - val_loss: 5.9689e-06\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 280/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2730e-05 - val_loss: 5.9520e-06\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 281/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2626e-05 - val_loss: 5.9354e-06\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 282/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2523e-05 - val_loss: 5.9187e-06\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 283/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2421e-05 - val_loss: 5.9021e-06\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 284/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2320e-05 - val_loss: 5.8856e-06\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 285/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.2221e-05 - val_loss: 5.8692e-06\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 286/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.2122e-05 - val_loss: 5.8527e-06\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 287/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.2024e-05 - val_loss: 5.8364e-06\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 288/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1926e-05 - val_loss: 5.8201e-06\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 289/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1829e-05 - val_loss: 5.8040e-06\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 290/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.1733e-05 - val_loss: 5.7879e-06\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 291/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1636e-05 - val_loss: 5.7719e-06\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 292/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1540e-05 - val_loss: 5.7560e-06\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 293/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1442e-05 - val_loss: 5.7403e-06\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 294/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.1345e-05 - val_loss: 5.7245e-06\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 295/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1247e-05 - val_loss: 5.7091e-06\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 296/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.1148e-05 - val_loss: 5.6937e-06\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 297/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.1049e-05 - val_loss: 5.6785e-06\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 298/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.0948e-05 - val_loss: 5.6634e-06\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 299/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.0848e-05 - val_loss: 5.6484e-06\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 300/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.0748e-05 - val_loss: 5.6337e-06\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 301/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.0647e-05 - val_loss: 5.6191e-06\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 302/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 5.0547e-05 - val_loss: 5.6047e-06\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 303/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.0447e-05 - val_loss: 5.5903e-06\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 304/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.0348e-05 - val_loss: 5.5761e-06\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 305/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.0250e-05 - val_loss: 5.5621e-06\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 306/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 5.0153e-05 - val_loss: 5.5482e-06\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 307/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 5.0058e-05 - val_loss: 5.5342e-06\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 308/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.9965e-05 - val_loss: 5.5204e-06\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 309/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9873e-05 - val_loss: 5.5066e-06\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 310/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9783e-05 - val_loss: 5.4929e-06\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 311/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9695e-05 - val_loss: 5.4792e-06\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 312/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.9609e-05 - val_loss: 5.4656e-06\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 313/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9524e-05 - val_loss: 5.4519e-06\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 314/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.9441e-05 - val_loss: 5.4384e-06\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 315/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9358e-05 - val_loss: 5.4248e-06\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 316/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.9277e-05 - val_loss: 5.4113e-06\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 317/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9195e-05 - val_loss: 5.3978e-06\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 88ms/step - loss: 4.9114e-05 - val_loss: 5.3844e-06\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 319/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.9032e-05 - val_loss: 5.3711e-06\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 320/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.8950e-05 - val_loss: 5.3579e-06\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 321/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.8866e-05 - val_loss: 5.3448e-06\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 322/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.8781e-05 - val_loss: 5.3319e-06\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 323/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.8695e-05 - val_loss: 5.3192e-06\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 324/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.8607e-05 - val_loss: 5.3065e-06\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 325/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.8518e-05 - val_loss: 5.2942e-06\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 326/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.8428e-05 - val_loss: 5.2819e-06\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 327/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.8336e-05 - val_loss: 5.2699e-06\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 328/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.8244e-05 - val_loss: 5.2581e-06\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 329/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.8150e-05 - val_loss: 5.2465e-06\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 330/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.8057e-05 - val_loss: 5.2350e-06\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 331/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.7964e-05 - val_loss: 5.2238e-06\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 332/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7873e-05 - val_loss: 5.2127e-06\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 333/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.7783e-05 - val_loss: 5.2016e-06\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 334/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7694e-05 - val_loss: 5.1907e-06\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 335/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.7609e-05 - val_loss: 5.1798e-06\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 336/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7526e-05 - val_loss: 5.1691e-06\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 337/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.7447e-05 - val_loss: 5.1582e-06\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 338/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7370e-05 - val_loss: 5.1475e-06\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 339/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7296e-05 - val_loss: 5.1367e-06\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 340/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.7224e-05 - val_loss: 5.1259e-06\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 341/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7155e-05 - val_loss: 5.1151e-06\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 342/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.7087e-05 - val_loss: 5.1043e-06\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 343/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7022e-05 - val_loss: 5.0935e-06\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 344/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6957e-05 - val_loss: 5.0827e-06\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 345/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.6892e-05 - val_loss: 5.0719e-06\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 346/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.6826e-05 - val_loss: 5.0613e-06\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 347/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6759e-05 - val_loss: 5.0506e-06\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 348/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.6690e-05 - val_loss: 5.0402e-06\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 349/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6618e-05 - val_loss: 5.0298e-06\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 350/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.6543e-05 - val_loss: 5.0197e-06\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 351/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.6465e-05 - val_loss: 5.0097e-06\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 352/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6384e-05 - val_loss: 5.0000e-06\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.00001 to 0.00001, saving model to model_checkpoint_gru.h5\n",
      "Epoch 353/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6299e-05 - val_loss: 4.9905e-06\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.00001 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 354/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6210e-05 - val_loss: 4.9813e-06\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 355/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6120e-05 - val_loss: 4.9724e-06\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 356/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6027e-05 - val_loss: 4.9637e-06\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 89ms/step - loss: 4.5934e-05 - val_loss: 4.9552e-06\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 358/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.5840e-05 - val_loss: 4.9470e-06\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 359/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.5748e-05 - val_loss: 4.9390e-06\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 360/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.5657e-05 - val_loss: 4.9311e-06\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 361/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.5570e-05 - val_loss: 4.9233e-06\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 362/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.5487e-05 - val_loss: 4.9155e-06\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 363/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.5409e-05 - val_loss: 4.9078e-06\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 364/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.5336e-05 - val_loss: 4.8999e-06\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 365/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.5269e-05 - val_loss: 4.8921e-06\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 366/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.5208e-05 - val_loss: 4.8840e-06\n",
      "\n",
      "Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 367/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.5153e-05 - val_loss: 4.8758e-06\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 368/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.5103e-05 - val_loss: 4.8675e-06\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 369/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.5058e-05 - val_loss: 4.8589e-06\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 370/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.5017e-05 - val_loss: 4.8501e-06\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 371/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4978e-05 - val_loss: 4.8411e-06\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 372/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4939e-05 - val_loss: 4.8321e-06\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 373/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4900e-05 - val_loss: 4.8229e-06\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 374/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4858e-05 - val_loss: 4.8137e-06\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 375/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4813e-05 - val_loss: 4.8045e-06\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 376/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4761e-05 - val_loss: 4.7954e-06\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 377/1000\n",
      "321/321 [==============================] - 28s 87ms/step - loss: 4.4702e-05 - val_loss: 4.7865e-06\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 378/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.4636e-05 - val_loss: 4.7779e-06\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 379/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.4561e-05 - val_loss: 4.7696e-06\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 380/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.4478e-05 - val_loss: 4.7616e-06\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 381/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4385e-05 - val_loss: 4.7541e-06\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 382/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.4286e-05 - val_loss: 4.7469e-06\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 383/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.4179e-05 - val_loss: 4.7402e-06\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 384/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4067e-05 - val_loss: 4.7339e-06\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 385/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3953e-05 - val_loss: 4.7281e-06\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 386/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3838e-05 - val_loss: 4.7226e-06\n",
      "\n",
      "Epoch 00386: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 387/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3724e-05 - val_loss: 4.7175e-06\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 388/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3615e-05 - val_loss: 4.7126e-06\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 389/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3513e-05 - val_loss: 4.7078e-06\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 390/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3420e-05 - val_loss: 4.7029e-06\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 391/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 4.3339e-05 - val_loss: 4.6981e-06\n",
      "\n",
      "Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 392/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3271e-05 - val_loss: 4.6929e-06\n",
      "\n",
      "Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 393/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3216e-05 - val_loss: 4.6874e-06\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 394/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3177e-05 - val_loss: 4.6815e-06\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 395/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3152e-05 - val_loss: 4.6750e-06\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 28s 88ms/step - loss: 4.3140e-05 - val_loss: 4.6679e-06\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 397/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.3140e-05 - val_loss: 4.6602e-06\n",
      "\n",
      "Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 398/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.3148e-05 - val_loss: 4.6518e-06\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 399/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.3162e-05 - val_loss: 4.6431e-06\n",
      "\n",
      "Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 400/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.3178e-05 - val_loss: 4.6337e-06\n",
      "\n",
      "Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 401/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.3192e-05 - val_loss: 4.6241e-06\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 402/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3199e-05 - val_loss: 4.6142e-06\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 403/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3197e-05 - val_loss: 4.6043e-06\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 404/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.3180e-05 - val_loss: 4.5946e-06\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 405/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.3145e-05 - val_loss: 4.5852e-06\n",
      "\n",
      "Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 406/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.3090e-05 - val_loss: 4.5762e-06\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 407/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3012e-05 - val_loss: 4.5679e-06\n",
      "\n",
      "Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 408/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2911e-05 - val_loss: 4.5602e-06\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 409/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2787e-05 - val_loss: 4.5534e-06\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 410/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 4.2641e-05 - val_loss: 4.5475e-06\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 411/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.2476e-05 - val_loss: 4.5425e-06\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 412/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 4.2295e-05 - val_loss: 4.5386e-06\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 413/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.2104e-05 - val_loss: 4.5355e-06\n",
      "\n",
      "Epoch 00413: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 414/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.1908e-05 - val_loss: 4.5332e-06\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 415/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1715e-05 - val_loss: 4.5318e-06\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 416/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1532e-05 - val_loss: 4.5311e-06\n",
      "\n",
      "Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 417/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1364e-05 - val_loss: 4.5308e-06\n",
      "\n",
      "Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 418/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1220e-05 - val_loss: 4.5304e-06\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 419/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1105e-05 - val_loss: 4.5299e-06\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 420/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.1025e-05 - val_loss: 4.5289e-06\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 421/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.0984e-05 - val_loss: 4.5269e-06\n",
      "\n",
      "Epoch 00421: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 422/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.0982e-05 - val_loss: 4.5237e-06\n",
      "\n",
      "Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 423/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.1021e-05 - val_loss: 4.5191e-06\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 424/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.1098e-05 - val_loss: 4.5129e-06\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 425/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1208e-05 - val_loss: 4.5052e-06\n",
      "\n",
      "Epoch 00425: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 426/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1346e-05 - val_loss: 4.4958e-06\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 427/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1505e-05 - val_loss: 4.4848e-06\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 428/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1673e-05 - val_loss: 4.4725e-06\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 429/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.1841e-05 - val_loss: 4.4590e-06\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 430/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.1998e-05 - val_loss: 4.4449e-06\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 431/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2130e-05 - val_loss: 4.4305e-06\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 432/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.2229e-05 - val_loss: 4.4163e-06\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 433/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.2284e-05 - val_loss: 4.4030e-06\n",
      "\n",
      "Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 434/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 4.2284e-05 - val_loss: 4.3909e-06\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2223e-05 - val_loss: 4.3802e-06\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 436/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2096e-05 - val_loss: 4.3710e-06\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 437/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.1901e-05 - val_loss: 4.3634e-06\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 438/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1639e-05 - val_loss: 4.3573e-06\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 439/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1313e-05 - val_loss: 4.3529e-06\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 440/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0933e-05 - val_loss: 4.3503e-06\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 441/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.0509e-05 - val_loss: 4.3500e-06\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 442/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0056e-05 - val_loss: 4.3523e-06\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00000\n",
      "Epoch 443/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.9593e-05 - val_loss: 4.3574e-06\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00000\n",
      "Epoch 444/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.9140e-05 - val_loss: 4.3653e-06\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00000\n",
      "Epoch 445/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.8721e-05 - val_loss: 4.3752e-06\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00000\n",
      "Epoch 446/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8358e-05 - val_loss: 4.3858e-06\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00000\n",
      "Epoch 447/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8074e-05 - val_loss: 4.3957e-06\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00000\n",
      "Epoch 448/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7888e-05 - val_loss: 4.4036e-06\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00000\n",
      "Epoch 449/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7814e-05 - val_loss: 4.4087e-06\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00000\n",
      "Epoch 450/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.7860e-05 - val_loss: 4.4106e-06\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00000\n",
      "Epoch 451/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8027e-05 - val_loss: 4.4092e-06\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00000\n",
      "Epoch 452/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8310e-05 - val_loss: 4.4047e-06\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00000\n",
      "Epoch 453/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8697e-05 - val_loss: 4.3976e-06\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00000\n",
      "Epoch 454/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.9171e-05 - val_loss: 4.3877e-06\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00000\n",
      "Epoch 455/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.9712e-05 - val_loss: 4.3752e-06\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00000\n",
      "Epoch 456/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0297e-05 - val_loss: 4.3600e-06\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00000\n",
      "Epoch 457/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0900e-05 - val_loss: 4.3419e-06\n",
      "\n",
      "Epoch 00457: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 458/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1495e-05 - val_loss: 4.3209e-06\n",
      "\n",
      "Epoch 00458: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 459/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2053e-05 - val_loss: 4.2973e-06\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 460/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2548e-05 - val_loss: 4.2724e-06\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 461/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2952e-05 - val_loss: 4.2492e-06\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 462/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3241e-05 - val_loss: 4.2312e-06\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 463/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3389e-05 - val_loss: 4.2208e-06\n",
      "\n",
      "Epoch 00463: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 464/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3378e-05 - val_loss: 4.2178e-06\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 465/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3192e-05 - val_loss: 4.2191e-06\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00000\n",
      "Epoch 466/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2821e-05 - val_loss: 4.2204e-06\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00000\n",
      "Epoch 467/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2264e-05 - val_loss: 4.2180e-06\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00000\n",
      "Epoch 468/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.1524e-05 - val_loss: 4.2100e-06\n",
      "\n",
      "Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 469/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0615e-05 - val_loss: 4.1975e-06\n",
      "\n",
      "Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 470/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.9560e-05 - val_loss: 4.1848e-06\n",
      "\n",
      "Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 471/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8390e-05 - val_loss: 4.1782e-06\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 472/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7150e-05 - val_loss: 4.1844e-06\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00000\n",
      "Epoch 473/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.5896e-05 - val_loss: 4.2067e-06\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00000\n",
      "Epoch 474/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.4703e-05 - val_loss: 4.2404e-06\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00000\n",
      "Epoch 475/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.3660e-05 - val_loss: 4.2745e-06\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00000\n",
      "Epoch 476/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2853e-05 - val_loss: 4.3001e-06\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00000\n",
      "Epoch 477/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.2348e-05 - val_loss: 4.3166e-06\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00000\n",
      "Epoch 478/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.2162e-05 - val_loss: 4.3295e-06\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00000\n",
      "Epoch 479/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2266e-05 - val_loss: 4.3435e-06\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00000\n",
      "Epoch 480/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2607e-05 - val_loss: 4.3591e-06\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00000\n",
      "Epoch 481/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.3140e-05 - val_loss: 4.3738e-06\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00000\n",
      "Epoch 482/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.3842e-05 - val_loss: 4.3847e-06\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00000\n",
      "Epoch 483/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.4710e-05 - val_loss: 4.3894e-06\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00000\n",
      "Epoch 484/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.5749e-05 - val_loss: 4.3862e-06\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00000\n",
      "Epoch 485/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.6954e-05 - val_loss: 4.3731e-06\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00000\n",
      "Epoch 486/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8308e-05 - val_loss: 4.3469e-06\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00000\n",
      "Epoch 487/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.9767e-05 - val_loss: 4.3053e-06\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00000\n",
      "Epoch 488/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1258e-05 - val_loss: 4.2509e-06\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00000\n",
      "Epoch 489/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2684e-05 - val_loss: 4.1953e-06\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00000\n",
      "Epoch 490/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3937e-05 - val_loss: 4.1507e-06\n",
      "\n",
      "Epoch 00490: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 491/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4934e-05 - val_loss: 4.1186e-06\n",
      "\n",
      "Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 492/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5640e-05 - val_loss: 4.0927e-06\n",
      "\n",
      "Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 493/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6064e-05 - val_loss: 4.0772e-06\n",
      "\n",
      "Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 494/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.6236e-05 - val_loss: 4.0850e-06\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00000\n",
      "Epoch 495/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6181e-05 - val_loss: 4.1176e-06\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00000\n",
      "Epoch 496/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5905e-05 - val_loss: 4.1611e-06\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00000\n",
      "Epoch 497/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5385e-05 - val_loss: 4.1970e-06\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00000\n",
      "Epoch 498/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4596e-05 - val_loss: 4.2114e-06\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00000\n",
      "Epoch 499/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3523e-05 - val_loss: 4.1984e-06\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00000\n",
      "Epoch 500/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.2168e-05 - val_loss: 4.1613e-06\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00000\n",
      "Epoch 501/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.0546e-05 - val_loss: 4.1096e-06\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00000\n",
      "Epoch 502/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.8688e-05 - val_loss: 4.0581e-06\n",
      "\n",
      "Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 503/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.6643e-05 - val_loss: 4.0257e-06\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 504/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.4489e-05 - val_loss: 4.0304e-06\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00000\n",
      "Epoch 505/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2342e-05 - val_loss: 4.0728e-06\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00000\n",
      "Epoch 506/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.0379e-05 - val_loss: 4.1289e-06\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00000\n",
      "Epoch 507/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.8803e-05 - val_loss: 4.1769e-06\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00000\n",
      "Epoch 508/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.7738e-05 - val_loss: 4.2195e-06\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00000\n",
      "Epoch 509/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.7133e-05 - val_loss: 4.2666e-06\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00000\n",
      "Epoch 510/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.6806e-05 - val_loss: 4.3163e-06\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00000\n",
      "Epoch 511/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.6603e-05 - val_loss: 4.3606e-06\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00000\n",
      "Epoch 512/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.6482e-05 - val_loss: 4.3903e-06\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00000\n",
      "Epoch 513/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.6476e-05 - val_loss: 4.3991e-06\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00000\n",
      "Epoch 514/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 2.6633e-05 - val_loss: 4.3877e-06\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00000\n",
      "Epoch 515/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 2.6988e-05 - val_loss: 4.3626e-06\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00000\n",
      "Epoch 516/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 2.7560e-05 - val_loss: 4.3313e-06\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00000\n",
      "Epoch 517/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.8359e-05 - val_loss: 4.2991e-06\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00000\n",
      "Epoch 518/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.9398e-05 - val_loss: 4.2693e-06\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00000\n",
      "Epoch 519/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.0698e-05 - val_loss: 4.2447e-06\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00000\n",
      "Epoch 520/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2296e-05 - val_loss: 4.2283e-06\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00000\n",
      "Epoch 521/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.4223e-05 - val_loss: 4.2226e-06\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.00000\n",
      "Epoch 522/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.6478e-05 - val_loss: 4.2233e-06\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00000\n",
      "Epoch 523/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.8994e-05 - val_loss: 4.2120e-06\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00000\n",
      "Epoch 524/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.1609e-05 - val_loss: 4.1585e-06\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.00000\n",
      "Epoch 525/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.4073e-05 - val_loss: 4.0679e-06\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.00000\n",
      "Epoch 526/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.6108e-05 - val_loss: 3.9916e-06\n",
      "\n",
      "Epoch 00526: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 527/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 29s 90ms/step - loss: 4.7504e-05 - val_loss: 3.9444e-06\n",
      "\n",
      "Epoch 00527: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 528/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.8248e-05 - val_loss: 3.9200e-06\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 529/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.8485e-05 - val_loss: 3.9433e-06\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.00000\n",
      "Epoch 530/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.8404e-05 - val_loss: 4.0130e-06\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.00000\n",
      "Epoch 531/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.8095e-05 - val_loss: 4.0982e-06\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.00000\n",
      "Epoch 532/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.7526e-05 - val_loss: 4.1637e-06\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.00000\n",
      "Epoch 533/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6653e-05 - val_loss: 4.1853e-06\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.00000\n",
      "Epoch 534/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5452e-05 - val_loss: 4.1579e-06\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.00000\n",
      "Epoch 535/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 4.3906e-05 - val_loss: 4.0938e-06\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.00000\n",
      "Epoch 536/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2019e-05 - val_loss: 4.0136e-06\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.00000\n",
      "Epoch 537/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.9826e-05 - val_loss: 3.9359e-06\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.00000\n",
      "Epoch 538/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7388e-05 - val_loss: 3.8771e-06\n",
      "\n",
      "Epoch 00538: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 539/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.4790e-05 - val_loss: 3.8556e-06\n",
      "\n",
      "Epoch 00539: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 540/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2145e-05 - val_loss: 3.8834e-06\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.00000\n",
      "Epoch 541/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.9625e-05 - val_loss: 3.9452e-06\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.00000\n",
      "Epoch 542/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.7478e-05 - val_loss: 4.0132e-06\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.00000\n",
      "Epoch 543/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.5918e-05 - val_loss: 4.0786e-06\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.00000\n",
      "Epoch 544/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.4949e-05 - val_loss: 4.1473e-06\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.00000\n",
      "Epoch 545/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.4342e-05 - val_loss: 4.2200e-06\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.00000\n",
      "Epoch 546/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.3867e-05 - val_loss: 4.2926e-06\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.00000\n",
      "Epoch 547/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.3482e-05 - val_loss: 4.3443e-06\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.00000\n",
      "Epoch 548/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.3244e-05 - val_loss: 4.3511e-06\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.00000\n",
      "Epoch 549/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.3214e-05 - val_loss: 4.3157e-06\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.00000\n",
      "Epoch 550/1000\n",
      "321/321 [==============================] - 31s 96ms/step - loss: 2.3431e-05 - val_loss: 4.2625e-06\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.00000\n",
      "Epoch 551/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 2.3892e-05 - val_loss: 4.2169e-06\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.00000\n",
      "Epoch 552/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 2.4546e-05 - val_loss: 4.1911e-06\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.00000\n",
      "Epoch 553/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 2.5320e-05 - val_loss: 4.1823e-06\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.00000\n",
      "Epoch 554/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 2.6165e-05 - val_loss: 4.1774e-06\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.00000\n",
      "Epoch 555/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 2.7103e-05 - val_loss: 4.1652e-06\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.00000\n",
      "Epoch 556/1000\n",
      "321/321 [==============================] - 31s 96ms/step - loss: 2.8210e-05 - val_loss: 4.1441e-06\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.00000\n",
      "Epoch 557/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 2.9585e-05 - val_loss: 4.1209e-06\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.00000\n",
      "Epoch 558/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 3.1310e-05 - val_loss: 4.1046e-06\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.00000\n",
      "Epoch 559/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 3.3434e-05 - val_loss: 4.1009e-06\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.00000\n",
      "Epoch 560/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 3.5950e-05 - val_loss: 4.1067e-06\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.00000\n",
      "Epoch 561/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.8754e-05 - val_loss: 4.0959e-06\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.00000\n",
      "Epoch 562/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.1613e-05 - val_loss: 4.0313e-06\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.00000\n",
      "Epoch 563/1000\n",
      "321/321 [==============================] - 28s 88ms/step - loss: 4.4201e-05 - val_loss: 3.9358e-06\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.00000\n",
      "Epoch 564/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 4.6177e-05 - val_loss: 3.8665e-06\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.00000\n",
      "Epoch 565/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7372e-05 - val_loss: 3.8160e-06\n",
      "\n",
      "Epoch 00565: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 566/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.7878e-05 - val_loss: 3.7987e-06\n",
      "\n",
      "Epoch 00566: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 567/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.7935e-05 - val_loss: 3.8384e-06\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.00000\n",
      "Epoch 568/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7744e-05 - val_loss: 3.9142e-06\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.00000\n",
      "Epoch 569/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.7313e-05 - val_loss: 3.9877e-06\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.00000\n",
      "Epoch 570/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6588e-05 - val_loss: 4.0252e-06\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.00000\n",
      "Epoch 571/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5533e-05 - val_loss: 4.0114e-06\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.00000\n",
      "Epoch 572/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4123e-05 - val_loss: 3.9547e-06\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.00000\n",
      "Epoch 573/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.2342e-05 - val_loss: 3.8769e-06\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.00000\n",
      "Epoch 574/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.0210e-05 - val_loss: 3.8010e-06\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.00000\n",
      "Epoch 575/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 29s 90ms/step - loss: 3.7786e-05 - val_loss: 3.7436e-06\n",
      "\n",
      "Epoch 00575: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 576/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 3.5158e-05 - val_loss: 3.7194e-06\n",
      "\n",
      "Epoch 00576: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 577/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.2433e-05 - val_loss: 3.7414e-06\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.00000\n",
      "Epoch 578/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 2.9759e-05 - val_loss: 3.8019e-06\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.00000\n",
      "Epoch 579/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.7361e-05 - val_loss: 3.8760e-06\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.00000\n",
      "Epoch 580/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.5495e-05 - val_loss: 3.9524e-06\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.00000\n",
      "Epoch 581/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.4267e-05 - val_loss: 4.0325e-06\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.00000\n",
      "Epoch 582/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.3515e-05 - val_loss: 4.1149e-06\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.00000\n",
      "Epoch 583/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.2963e-05 - val_loss: 4.1977e-06\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.00000\n",
      "Epoch 584/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.2491e-05 - val_loss: 4.2683e-06\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.00000\n",
      "Epoch 585/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.2141e-05 - val_loss: 4.2926e-06\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.00000\n",
      "Epoch 586/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.1984e-05 - val_loss: 4.2579e-06\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.00000\n",
      "Epoch 587/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.2080e-05 - val_loss: 4.1873e-06\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.00000\n",
      "Epoch 588/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.2456e-05 - val_loss: 4.1168e-06\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.00000\n",
      "Epoch 589/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.3078e-05 - val_loss: 4.0734e-06\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.00000\n",
      "Epoch 590/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.3853e-05 - val_loss: 4.0662e-06\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.00000\n",
      "Epoch 591/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.4669e-05 - val_loss: 4.0847e-06\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.00000\n",
      "Epoch 592/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 2.5470e-05 - val_loss: 4.1047e-06\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.00000\n",
      "Epoch 593/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.6305e-05 - val_loss: 4.1079e-06\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.00000\n",
      "Epoch 594/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 2.7297e-05 - val_loss: 4.0929e-06\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.00000\n",
      "Epoch 595/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.8579e-05 - val_loss: 4.0709e-06\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.00000\n",
      "Epoch 596/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 3.0251e-05 - val_loss: 4.0548e-06\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.00000\n",
      "Epoch 597/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 3.2368e-05 - val_loss: 4.0528e-06\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.00000\n",
      "Epoch 598/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 3.4928e-05 - val_loss: 4.0622e-06\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.00000\n",
      "Epoch 599/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 3.7819e-05 - val_loss: 4.0521e-06\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.00000\n",
      "Epoch 600/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.0781e-05 - val_loss: 3.9774e-06\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.00000\n",
      "Epoch 601/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.3440e-05 - val_loss: 3.8682e-06\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.00000\n",
      "Epoch 602/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.5414e-05 - val_loss: 3.7928e-06\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.00000\n",
      "Epoch 603/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6532e-05 - val_loss: 3.7327e-06\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.00000\n",
      "Epoch 604/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6937e-05 - val_loss: 3.7017e-06\n",
      "\n",
      "Epoch 00604: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 605/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.6923e-05 - val_loss: 3.7256e-06\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.00000\n",
      "Epoch 606/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6693e-05 - val_loss: 3.7845e-06\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.00000\n",
      "Epoch 607/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.6230e-05 - val_loss: 3.8409e-06\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.00000\n",
      "Epoch 608/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5474e-05 - val_loss: 3.8631e-06\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.00000\n",
      "Epoch 609/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.4382e-05 - val_loss: 3.8391e-06\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.00000\n",
      "Epoch 610/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.2919e-05 - val_loss: 3.7799e-06\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.00000\n",
      "Epoch 611/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.1069e-05 - val_loss: 3.7087e-06\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.00000\n",
      "Epoch 612/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 3.8859e-05 - val_loss: 3.6477e-06\n",
      "\n",
      "Epoch 00612: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 613/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 3.6357e-05 - val_loss: 3.6126e-06\n",
      "\n",
      "Epoch 00613: val_loss improved from 0.00000 to 0.00000, saving model to model_checkpoint_gru.h5\n",
      "Epoch 614/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 3.3660e-05 - val_loss: 3.6170e-06\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.00000\n",
      "Epoch 615/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 3.0890e-05 - val_loss: 3.6652e-06\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.00000\n",
      "Epoch 616/1000\n",
      "321/321 [==============================] - 28s 89ms/step - loss: 2.8222e-05 - val_loss: 3.7400e-06\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.00000\n",
      "Epoch 617/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.5910e-05 - val_loss: 3.8241e-06\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.00000\n",
      "Epoch 618/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 2.4190e-05 - val_loss: 3.9155e-06\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.00000\n",
      "Epoch 619/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 2.3085e-05 - val_loss: 4.0098e-06\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.00000\n",
      "Epoch 620/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.2368e-05 - val_loss: 4.0987e-06\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.00000\n",
      "Epoch 621/1000\n",
      "321/321 [==============================] - 29s 92ms/step - loss: 2.1785e-05 - val_loss: 4.1848e-06\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.00000\n",
      "Epoch 622/1000\n",
      "321/321 [==============================] - 29s 91ms/step - loss: 2.1289e-05 - val_loss: 4.2448e-06\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.00000\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 30s 93ms/step - loss: 2.0945e-05 - val_loss: 4.2367e-06\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.00000\n",
      "Epoch 624/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 2.0829e-05 - val_loss: 4.1598e-06\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.00000\n",
      "Epoch 625/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 2.1010e-05 - val_loss: 4.0516e-06\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.00000\n",
      "Epoch 626/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 2.1514e-05 - val_loss: 3.9559e-06\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.00000\n",
      "Epoch 627/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 2.2295e-05 - val_loss: 3.9060e-06\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.00000\n",
      "Epoch 628/1000\n",
      "321/321 [==============================] - 30s 94ms/step - loss: 2.3214e-05 - val_loss: 3.9161e-06\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.00000\n",
      "Epoch 629/1000\n",
      "321/321 [==============================] - 31s 95ms/step - loss: 2.4083e-05 - val_loss: 3.9744e-06\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.00000\n",
      "Epoch 630/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 2.4789e-05 - val_loss: 4.0432e-06\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.00000\n",
      "Epoch 631/1000\n",
      "321/321 [==============================] - 31s 95ms/step - loss: 2.5389e-05 - val_loss: 4.0845e-06\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.00000\n",
      "Epoch 632/1000\n",
      "321/321 [==============================] - 31s 96ms/step - loss: 2.6066e-05 - val_loss: 4.0886e-06\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.00000\n",
      "Epoch 633/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 2.7010e-05 - val_loss: 4.0701e-06\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.00000\n",
      "Epoch 634/1000\n",
      "321/321 [==============================] - 31s 96ms/step - loss: 2.8348e-05 - val_loss: 4.0491e-06\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.00000\n",
      "Epoch 635/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 3.0155e-05 - val_loss: 4.0400e-06\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.00000\n",
      "Epoch 636/1000\n",
      "321/321 [==============================] - 30s 95ms/step - loss: 3.2463e-05 - val_loss: 4.0483e-06\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.00000\n",
      "Epoch 637/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 3.5238e-05 - val_loss: 4.0582e-06\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.00000\n",
      "Epoch 638/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 3.8291e-05 - val_loss: 4.0169e-06\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.00000\n",
      "Epoch 639/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 4.1264e-05 - val_loss: 3.8950e-06\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.00000\n",
      "Epoch 640/1000\n",
      "321/321 [==============================] - 30s 92ms/step - loss: 4.3708e-05 - val_loss: 3.7820e-06\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.00000\n",
      "Epoch 641/1000\n",
      "321/321 [==============================] - 29s 89ms/step - loss: 4.5266e-05 - val_loss: 3.7094e-06\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.00000\n",
      "Epoch 642/1000\n",
      "321/321 [==============================] - 29s 90ms/step - loss: 4.5941e-05 - val_loss: 3.6443e-06\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.00000\n",
      "Epoch 643/1000\n",
      "321/321 [==============================] - 30s 93ms/step - loss: 4.6027e-05 - val_loss: 3.6216e-06\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.00000\n"
     ]
    }
   ],
   "source": [
    "path_checkpoint1 = \"model_checkpoint_gru.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=30)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint1,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model1.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GrlUegR-83A"
   },
   "source": [
    "### 3.2 Train and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UBeRFY2a-83A"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAceElEQVR4nO3df5BU5Z3v8feXmQFWQWdAUAKyAwmrIuCII5m7RNC4Kj+SoKWmICpgXFlvxFpjlsjGihevZUmIrl4SIlc2uPhbVs3KDRhXjWS0SiNgBgOC8kMMAwgDCoGgYX587x99umm6e2Z6ftHTPp9XVVefPuc5p7+nC/rTz/Oc6TZ3R0REwtMl1wWIiEhuKABERAKlABARCZQCQEQkUAoAEZFAFea6gJY45ZRTvLS0NNdliIjklTVr1ux19z6p6/MqAEpLS1m9enWuyxARyStm9lGm9RoCEhEJlAJARCRQCgARkUDl1RyAiHxx1dbWUl1dzeeff57rUvJW9+7dGTBgAEVFRVm1VwCISKdQXV1Nz549KS0txcxyXU7ecXf27dtHdXU1gwYNymofDQGJSKfw+eef07t3b735t5KZ0bt37xb1oBQAItJp6M2/bVr6+oURADt+Devn5roKEZFOJYwA2PkibLwv11WISCe2f/9+fvGLX7Rq3wkTJrB///6s28+ZM4f77sv9e1IYAYC6lSLStKYCoL6+vsl9V6xYQXFxcUeU1aECCQBAv3wmIk2YPXs2W7ZsoaysjFmzZrFy5UouuugivvOd7zB8+HAALr/8cs477zzOPvtsHn744cS+paWl7N27l23btnHWWWdx4403cvbZZ3PppZfy2WefNfm8VVVVVFRUMGLECK644go+/fRTAObPn8/QoUMZMWIEkydPBuB3v/sdZWVllJWVce6553Lw4ME2nXMYl4GaAQoAkbyx5lb4tKp9j1lSBuc92OjmuXPnsm7dOqqqYs+7cuVK3n77bdatW5e4rHLx4sX06tWLzz77jPPPP58rr7yS3r17H3OcTZs28dRTT7Fo0SK+/e1v89xzz3Httdc2+rxTp07lZz/7GWPHjuXOO+/krrvu4sEHH2Tu3Ll8+OGHdOvWLTG8dN9997FgwQJGjx7NoUOH6N69e5tekqx6AGY2zszeN7PNZjY7w3Yzs/nR9nfNbGS0/nQze83MNpjZejP756R9epnZy2a2KbovadOZNH0GHXdoEfnCGjVq1DHX1M+fP59zzjmHiooKtm/fzqZNm9L2GTRoEGVlZQCcd955bNu2rdHjHzhwgP379zN27FgApk2bRmVlJQAjRozgmmuu4fHHH6ewMPZZffTo0dx2223Mnz+f/fv3J9a3VrN7m1kBsAC4BKgGVpnZMnd/L6nZeGBIdPsq8FB0Xwf8wN3fMbOewBozeznadzbwqrvPjUJlNnB7m86mKRoCEskfTXxSP55OPPHExPLKlSt55ZVXePPNNznhhBO48MILM15z361bt8RyQUFBs0NAjVm+fDmVlZUsW7aMu+++m/Xr1zN79mwmTpzIihUrqKio4JVXXuHMM89s1fEhux7AKGCzu2919yPA08CklDaTgEc95i2g2Mz6ufsud38HwN0PAhuA/kn7LImWlwCXt/osmqUhIBFpWs+ePZscUz9w4AAlJSWccMIJbNy4kbfeeqvNz3nyySdTUlLC66+/DsBjjz3G2LFjaWhoYPv27Vx00UXMmzeP/fv3c+jQIbZs2cLw4cO5/fbbKS8vZ+PGjW16/mz6D/2B7UmPq4l9um+uTX9gV3yFmZUC5wK/j1ad6u67ANx9l5n1zfTkZjYDmAEwcODALMrNeBAUACLSlN69ezN69GiGDRvG+PHjmThx4jHbx40bx8KFCxkxYgRnnHEGFRUV7fK8S5Ys4aabbuLw4cMMHjyYRx55hPr6eq699loOHDiAu/P973+f4uJifvzjH/Paa69RUFDA0KFDGT9+fJue27yZoREzuxq4zN3/MXp8HTDK3W9JarMcuNfd34gevwr80N3XRI97AL8D7nH356N1+929OOkYn7p7k/MA5eXl3qofhFnzfdi6GK4+0PJ9ReS42LBhA2eddVauy8h7mV5HM1vj7uWpbbMZAqoGTk96PADYmW0bMysCngOeiL/5R3abWb+oTT9gTxa1tJ7mAEREjpFNAKwChpjZIDPrCkwGlqW0WQZMja4GqgAORMM6BvwS2ODu/5Zhn2nR8jTghVafRbM0BCQikqrZOQB3rzOzmcBLQAGw2N3Xm9lN0faFwApgArAZOAxcH+0+GrgO+KOZxS/q/ZG7rwDmAkvN7AbgT8DV7XdaKfQFUyIiabK6iDR6w16Rsm5h0rIDN2fY7w0auQjf3fcBF7ek2LZRD0BEJFkgXwVhmgMQEUkRRgDoMlARkTRhBIC+CkJEOkCPHj1atL6zCSQAQD0AEZFjBRIAmgMQkabdfvvtx/wewJw5c7j//vs5dOgQF198MSNHjmT48OG88EL2V6y7O7NmzWLYsGEMHz6cZ555BoBdu3YxZswYysrKGDZsGK+//jr19fVMnz490faBBx5o93NMFdDXQYtIvrj1Vqhq52+DLiuDB5v4jrnJkydz66238r3vfQ+ApUuX8pvf/Ibu3bvzq1/9ipNOOom9e/dSUVHBt771rax+f/f555+nqqqKtWvXsnfvXs4//3zGjBnDk08+yWWXXcYdd9xBfX09hw8fpqqqih07drBu3TqAFv3CWGuFEQCAhoBEpCnnnnsue/bsYefOndTU1FBSUsLAgQOpra3lRz/6EZWVlXTp0oUdO3awe/duTjvttGaP+cYbbzBlyhQKCgo49dRTGTt2LKtWreL888/nu9/9LrW1tVx++eWUlZUxePBgtm7dyi233MLEiRO59NJLO/ycAwkAXQUkkk+a+qTeka666iqeffZZPv7448SvcD3xxBPU1NSwZs0aioqKKC0tzfg10Jk09l1rY8aMobKykuXLl3Pdddcxa9Yspk6dytq1a3nppZdYsGABS5cuZfHixe12bploDkBEJDJ58mSefvppnn32Wa666iog9jXQffv2paioiNdee42PPvoo6+ONGTOGZ555hvr6empqaqisrGTUqFF89NFH9O3blxtvvJEbbriBd955h71799LQ0MCVV17J3XffzTvvvNNRp5kQRg9AcwAikoWzzz6bgwcP0r9/f/r16wfANddcwze/+U3Ky8spKytr0Q+wXHHFFbz55pucc845mBnz5s3jtNNOY8mSJfz0pz+lqKiIHj168Oijj7Jjxw6uv/56GhoaALj33ns75ByTNft10J1Jq78Oeu0d8N5PYEpd+xclIu1CXwfdPtr766C/ADQHICKSKqAAEBGRZIEEAJoEFskD+TQk3Rm19PULIwD0ZXAinV737t3Zt2+fQqCV3J19+/bRvXv3rPcJ4yogDQGJdHoDBgygurqampqaXJeSt7p3786AAQOybh9IAIhIZ1dUVMSgQYNyXUZQwhgCivcA1LUUEUkIIwASfwimABARiQsjADQHICKSJpAAiGgISEQkIZAA0BCQiEiqMAJAXwYnIpImjABIUA9ARCQukADQZaAiIqnCCABdBioikiaMANBloCIiaQIJgDj1AERE4gIJAM0BiIikCiMAdBmoiEiaMAIgQT0AEZG4QAJAVwGJiKQKKwA0ByAikhBGAGgOQEQkTRgBkKAegIhIXCABoDkAEZFUgQWAiIjEBRIAEU0Ci4gkhBEA+jI4EZE0WQWAmY0zs/fNbLOZzc6w3cxsfrT9XTMbmbRtsZntMbN1KfvMMbMdZlYV3Sa0/XQaPYPoXgEgIhLXbACYWQGwABgPDAWmmNnQlGbjgSHRbQbwUNK2/wDGNXL4B9y9LLqtaGHtLaA5ABGRVNn0AEYBm919q7sfAZ4GJqW0mQQ86jFvAcVm1g/A3SuBT9qz6FbTHICISEI2AdAf2J70uDpa19I2mcyMhowWm1lJpgZmNsPMVpvZ6pqamiwOmfEg0YICQEQkLpsAyDR+kvpOmk2bVA8BXwbKgF3A/ZkaufvD7l7u7uV9+vRprtZGaAhIRCRVNgFQDZye9HgAsLMVbY7h7rvdvd7dG4BFxIaaOpaGgEREErIJgFXAEDMbZGZdgcnAspQ2y4Cp0dVAFcABd9/V1EHjcwSRK4B1jbVtOw0BiYikKmyugbvXmdlM4CWgAFjs7uvN7KZo+0JgBTAB2AwcBq6P729mTwEXAqeYWTXwv9z9l8A8Mysj9q68DfindjyvY2kOQEQkTbMBABBdorkiZd3CpGUHbm5k3ymNrL8u+zLbSnMAIiKpwvhL4DjNAYiIJIQRABoCEhFJE0YAaAhIRCRNIAEQpx6AiEhcIAGg3wQWEUkVRgBoDkBEJE0YASAiImkCCQD1AEREUoUVAJoDEBFJCCMATJeBioikCiMAEtQDEBGJCyQANAcgIpIqsAAQEZG4QAIgoklgEZGEMAJAfwgmIpImjADQHICISJrAAkBEROICCYCI5gBERBLCCADNAYiIpAkjADQEJCKSJpAAiGgISEQkIZAA0BCQiEiqMAJAcwAiImnCCADNAYiIpAkkACKaAxARSQgkADQEJCKSKowA0A/CiIikCSMAEtQDEBGJCyQA9JvAIiKpwggAXQYqIpImjADQZaAiImkCCYA49QBEROICCQDNAYiIpAojAHQZqIhImjACIEE9ABGRuEACQFcBiYikCisANAcgIpIQRgBoDkBEJE1WAWBm48zsfTPbbGazM2w3M5sfbX/XzEYmbVtsZnvMbF3KPr3M7GUz2xTdl7T9dJqjHoCISFyzAWBmBcACYDwwFJhiZkNTmo0HhkS3GcBDSdv+AxiX4dCzgVfdfQjwavS4g2gOQEQkVTY9gFHAZnff6u5HgKeBSSltJgGPesxbQLGZ9QNw90rgkwzHnQQsiZaXAJe35gSyoyEgEZFU2QRAf2B70uPqaF1L26Q61d13AUT3fbOopW00CSwikpBNAGT6+Jz6TppNm1YxsxlmttrMVtfU1LT2IO1ZkojIF0I2AVANnJ70eACwsxVtUu2ODxNF93syNXL3h9293N3L+/Tpk0W5megyUBGRVNkEwCpgiJkNMrOuwGRgWUqbZcDU6GqgCuBAfHinCcuAadHyNOCFFtTdQpoDEBFJ1WwAuHsdMBN4CdgALHX39WZ2k5ndFDVbAWwFNgOLgO/F9zezp4A3gTPMrNrMbog2zQUuMbNNwCXR4w6mHoCISFxhNo3cfQWxN/nkdQuTlh24uZF9pzSyfh9wcdaVtoXmAERE0oTxl8AaAhIRSRNIAEQ0CSwikhBIAGgISEQkVRgBoDkAEZE0YQSAiIikCSQA9IdgIiKpwggADQGJiKQJIwB0GaiISJpAAiBOPQARkbhAAkBzACIiqcIIAP0msIhImjACIEE9ABGRuEACQFcBiYikCisANAcgIpIQRgBoDkBEJE0YAZCgHoCISFwgAaA5ABGRVIEFgIiIxAUSABFNAouIJIQRAPoyOBGRNGEEgC4DFRFJE1YAiIhIQiABEKcegIhIXBgBoDkAEZE0YQSAhoBERNIEEgARTQKLiCQEEgAaAhIRSRVGAGgOQEQkTRgBoDkAEZE0gQRARHMAIiIJYQSAhoBERNKEEQAaAhIRSRNIAMSpByAiEhdIAOjL4EREUoURAJoDEBFJE0YAaA5ARCRNIAEQpx6AiEhcIAGgOQARkVRhBIBpCEhEJFVWAWBm48zsfTPbbGazM2w3M5sfbX/XzEY2t6+ZzTGzHWZWFd0mtM8pNUU9ABGRuGYDwMwKgAXAeGAoMMXMhqY0Gw8MiW4zgIey3PcBdy+LbivaejJNnEV0rwAQEYnLpgcwCtjs7lvd/QjwNDAppc0k4FGPeQsoNrN+We57HGgOQEQkVTYB0B/YnvS4OlqXTZvm9p0ZDRktNrOSTE9uZjPMbLWZra6pqcmi3IwHad1+IiJfYNkEQKZ3z9SP0o21aWrfh4AvA2XALuD+TE/u7g+7e7m7l/fp0yeLcpuiHoCISFw2AVANnJ70eACwM8s2je7r7rvdvd7dG4BFxIaLOsT8hb246sH/1BCQiEiSbAJgFTDEzAaZWVdgMrAspc0yYGp0NVAFcMDddzW1bzRHEHcFsK6N59KoTVu68dqGizrq8CIieamwuQbuXmdmM4GXgAJgsbuvN7Obou0LgRXABGAzcBi4vql9o0PPM7MyYuMy24B/as8TS1ZY6NTVF6IhIBGRo5oNAIDoEs0VKesWJi07cHO2+0brr2tRpW1QWAh1DQoAEZFkQfwlcGEh1NYVaQ5ARCRJEAFQVORRD0BEROKCCIDCQnDvQkODegAiInHBBABAXZ3+IExEJC6IACgqit3X1gVxuiIiWQniHbGwIDb0U1eX40JERDqRMAIg6gFoCEhE5KgwAiA+B1CvABARiQsiAIoKY0NAtbUKABGRuCACoLAw9savISARkaPCCIDEHEBu6xAR6UyCCICiaA5Al4GKiBwVxDtiYTQHoElgEZGjAgmA2H1dbW7rEBHpTMIIgK6xSYC62vocVyIi0nkEEQBF3boCUHtEXQARkbggAqCwazcA6o7oMiARkbhAAqAAgLpa9QBEROKCCID4t4GqByAiclQQARC/Cqj2iCaBRUTiggqAulr1AERE4gILAPUARETiggiAxByAegAiIglBBMDROQD9KLyISFxQAaAhIBGRo4IIgG6xvwPj87/GvgzOHV5+GaqqcliUiEiOBREAp5wSu9/zSU8A7r0XLr0URo6EFStyWJiISA4FEQBFRdD75IN8/Ekxf/5zLAC+/nU46yyYORP0B8IiEqIgAgDgtN6H2L2vB48ucQ4dgp/8BO65Bz78EJYvz3V1IiLHXzABcGrfOnZ92oef/7yBUaOgvBy+8Q340pdg0aJcVycicvwFEwD9+8Obm/6e9z8oYObM2LrCQrj+enjxRaiuzm19IiLHWzABMPnbsYH+gV/6C5MnH10/fXrsqqDHH89NXSIiuRJMAIy/8nRevuMbVD12V+IvgwG+8hX42tdgyZJYEIiIhCKYALCCIv7h4jpKDj4L3nDMtunTYeNG+P3vc1ObiEguBBMAAAyaDn/5ELYuOWb11VdDjx7w4IO5KUtEJBfCCoCBV0PfsbDmFti9MrH6pJPglltg6VJYvz535YmIHE9hBUCXAvj7J+GE0+G3F8Pb/xM+rwHgBz+I9QLuvDPHNYqIHCdhBQDACV+Cy96GITfDlkXw/74C7/2U3sV/5V/+BZ5/Ht5+O9dFioh0vPACAKCoJ5TPhwnroM8FUPVDWD6U265+nj59nFmzdEWQiHzxZRUAZjbOzN43s81mNjvDdjOz+dH2d81sZHP7mlkvM3vZzDZF9yXtc0otcPKZcOGv4aL/hoIT6PGHK7ln8v+mshIW3flfsPYOeHcObHkE9lTC4eq0K4hERPKVeTMfdc2sAPgAuASoBlYBU9z9vaQ2E4BbgAnAV4H/4+5fbWpfM5sHfOLuc6NgKHH325uqpby83FevXt3KU21GQz1se4yGDxZxyax7+O26C7ngzNfpdeI+Dhw+mf2Hi2nwLgw5bQt/97c1DCn9C72Ka+nZs56eJ9bTs2cDXbsWUNi1gIKCAgq7dqGgwCgs7EJBURcKCrpEywV0KeiCdSkEKwQrgMRyF8DADOgS3dvR9fHljOuz3CfR1qITj+7Njr4WqduO2Z7NtkzHbWn7DM/VqWtsbx10XMuzevU6RBysKDaP2Qpmtsbdy1PXF2ax7yhgs7tvjQ70NDAJeC+pzSTgUY+lyVtmVmxm/YDSJvadBFwY7b8EWAk0GQAdqksBDJ5Ol8HTeeFrcN998OKLF7D1M+fk4s8Z0P8QXneYP354AS+sKaGuPpuXLjtmDRiOWewGHPO40W0pbWLHanpb4zU0sY3jvF/aNk/ct98xk7Y1ccyOOm5rj3k8Nfe6HJca9Fok/N+fH+SCK77arsfM5l2sP7A96XE1sU/5zbXp38y+p7r7LgB332VmfTM9uZnNAGYADBw4MIty265HD5gzJ3aLJfrfRLeY2lr4059g/344dAgOHozdjhyBujqor4f6ugbq6pz62vrYfX1DbF2t09DQAO64N+ANDXiD416Pu4PH5h/c/dj7BoCUdfHlaFTKiS2ntonvFzt48pnGHmTuBMa3GaT+448eJo6Zae8Mz5N5W/IBGzsa0etlx7bP5pgZtx3zlOnH9KMLR58zy+MmtjX+SbCpt5KMr3d7acFhc/9214HzcC08bvxjV671PLV/ux8zmwDIdOapL2FjbbLZt0nu/jDwMMSGgFqyb0cpKoIvf7m5VvHpldZ12UREOlo2k8DVwOlJjwcAO7Ns09S+u6NhIqL7PdmXLSIibZVNAKwChpjZIDPrCkwGlqW0WQZMja4GqgAORMM7Te27DJgWLU8DXmjjuYiISAs0OwTk7nVmNhN4idh4xmJ3X29mN0XbFwIriF0BtBk4DFzf1L7RoecCS83sBuBPwNXtemYiItKkZi8D7Uw69DJQEZEvqMYuAw3zL4FFREQBICISKgWAiEigFAAiIoHKq0lgM6sBPmrl7qcAe9uxnOMtn+tX7bmTz/Xnc+3Quer/W3fvk7oyrwKgLcxsdaZZ8HyRz/Wr9tzJ5/rzuXbIj/o1BCQiEigFgIhIoEIKgIdzXUAb5XP9qj138rn+fK4d8qD+YOYARETkWCH1AEREJIkCQEQkUEEEQHM/ap9rZrbYzPaY2bqkdb3M7GUz2xTdlyRt+9foXN43s8tyU3WiltPN7DUz22Bm683sn6P1+VJ/dzN728zWRvXfFa3Pi/qjegrM7A9m9uvocV7UbmbbzOyPZlZlZqujdXlRe1RPsZk9a2Ybo3///yOf6gfiPx34xb0R+xrqLcBgoCuwFhia67pSahwDjATWJa2bB8yOlmcDP4mWh0bn0A0YFJ1bQQ5r7weMjJZ7Ah9ENeZL/Qb0iJaLgN8DFflSf1TTbcCTwK/z7N/ONuCUlHV5UXtU0xLgH6PlrkBxPtXv7kH0ABI/au/uR4D4D9N3Gu5eCXySsnoSsX9gRPeXJ61/2t3/6u4fEvsNhlHHpdAM3H2Xu78TLR8ENhD7Leh8qd/d/VD0sCi6OXlSv5kNACYC/560Oi9qb0Re1G5mJxH74PZLAHc/4u77yZP640IIgMZ+sL6zO9Vjv6pGdN83Wt9pz8fMSoFziX2Kzpv6oyGUKmI/S/qyu+dT/Q8CPwQaktblS+0O/LeZrTGzGdG6fKl9MFADPBINv/27mZ1I/tQPhBEAbf5h+k6mU56PmfUAngNudfc/N9U0w7qc1u/u9e5eRuw3q0eZ2bAmmnea+s3sG8Aed1+T7S4Z1uXytR/t7iOB8cDNZjamibadrfZCYsO2D7n7ucBfiA35NKaz1Q+EEQDZ/Kh9Z7TbzPoBRPd7ovWd7nzMrIjYm/8T7v58tDpv6o+LuvArgXHkR/2jgW+Z2TZiQ5tfN7PHyY/acfed0f0e4FfEhkTyonZi9VRHvUWAZ4kFQr7UD4QRANn8qH1ntAyYFi1PA15IWj/ZzLqZ2SBgCPB2DuoDwMyM2DjoBnf/t6RN+VJ/HzMrjpb/BvgHYCN5UL+7/6u7D3D3UmL/rn/r7teSB7Wb2Ylm1jO+DFwKrCMPagdw94+B7WZ2RrTqYuA98qT+hFzPQh+PG7EfrP+A2Mz7HbmuJ0N9TwG7gFpinxRuAHoDrwKbovteSe3viM7lfWB8jmv/GrGu7LtAVXSbkEf1jwD+ENW/DrgzWp8X9SfVdCFHrwLq9LUTG0NfG93Wx/9f5kPtSfWUAaujfzv/BZTkU/3urq+CEBEJVQhDQCIikoECQEQkUAoAEZFAKQBERAKlABARCZQCQEQkUAoAEZFA/X97EtU1qzM9rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_1 = history.history['loss']\n",
    "val_loss_1 = history.history['val_loss']\n",
    "plt.plot(train_loss_1, label='train loss', c='orange')\n",
    "plt.plot(val_loss_1, label='val loss', c='blue')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DvJQGhv-83B"
   },
   "source": [
    "### 3.3 Prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MWyRPkJ3-83B"
   },
   "outputs": [],
   "source": [
    "test_prediction_1 = []\n",
    "test_actual = []\n",
    "for x, y in dataset_test:\n",
    "    test_actual.append(y[0][0])\n",
    "    predict_res = model1.predict(x)[0][0]\n",
    "    test_prediction_1.append(predict_res)\n",
    "test_prediction_1 = np.array(test_prediction_1)\n",
    "test_actual = np.array(test_actual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxhU7Wqq-83B"
   },
   "source": [
    "### 3.4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "K9u7_k4f-83B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result evaluation\n",
      "RMSE:  0.01848193721655263\n",
      "MAPE:  0.020912596696768374\n",
      "MAE:   0.014663887806687982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "rmse1 = mean_squared_error(test_actual, test_prediction_1, squared=False)\n",
    "mape1 = mean_absolute_percentage_error(test_actual, test_prediction_1)\n",
    "mae1 = mean_absolute_error(test_actual, test_prediction_1)\n",
    "\n",
    "print('result evaluation')\n",
    "print('RMSE: ', rmse1)\n",
    "print('MAPE: ', mape1)\n",
    "print('MAE:  ', mae1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aqXYrbXr-83B",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = [x for x in range(test_actual.shape[0])]\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "sns.lineplot(x=x_axis, y=test_actual, label='actual close price', linewidth=1)\n",
    "sns.lineplot(x=x_axis, y=test_prediction_1, label='predicted close price', linewidth=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAUjwyK_-83B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment6_AUD_USD_GRU.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
